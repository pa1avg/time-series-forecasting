# -*- coding: utf-8 -*-
"""TSFF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ThFYU3L4gHNSmtA6fGrLTpYJOEqAT2k7
"""

# Commented out IPython magic to ensure Python compatibility.
#Import all the required modules
!pip install pmdarima
from pmdarima.arima import auto_arima
import pandas as pd
import numpy as np
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller,kpss
from sklearn.metrics import mean_squared_error, mean_absolute_error
from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.graphics.tsaplots import plot_acf,plot_pacf
from statsmodels.graphics.gofplots import qqplot
from scipy.stats import skew, kurtosis, shapiro
# %matplotlib inline
warnings.filterwarnings("ignore")

"""IMPORT DATA AND DATA PREPROCESSING"""

# Import Raw Data, Remove duplicates, Date-Time Split and setting the date format
data = pd.read_csv('coursework_data.csv')
data = data.drop_duplicates(subset=['Call_Date'])
data['Call_Volume'] = 1
data['Call_Date'] = pd.to_datetime(data['Call_Date'], format='%d/%m/%Y %H:%M:%S')
data['Date'] = data['Call_Date'].dt.date
data['Time'] = data['Call_Date'].dt.time
#Check for missing dates if any between the range
sd = '2019-03-01'
ed = '2019-09-30'
all_dates = pd.date_range(start=sd, end=ed)
my_dates = data['Call_Date'].dt.date.unique()
missing_dates = all_dates[~all_dates.isin(my_dates)]
if len(missing_dates) == 0:
    print("No Missing Dates.")
else:
    print("Missing Dates:")
    print(missing_dates)

# Extracting Date Properties like Day, Week Number, Weekday/Weekend and Month
data['Day'] = data['Call_Date'].dt.day
data['Day_Name'] = data['Call_Date'].dt.day_name()
data['Week'] = data['Call_Date'].dt.isocalendar().week-8
ifs = [(data['Day'] <= 7),(data['Day'] <= 14),(data['Day'] <= 21),(data['Day'] <= 31)]
choice = ['Week 1', 'Week 2', 'Week 3', 'Week 4']
ifs1 = [(data['Call_Date'].dt.dayofweek // 5 == 0),(data['Call_Date'].dt.dayofweek // 5 == 1)]
choice1 = ['Weekday', 'Weekend']
data['MonthlyWeek'] = np.select(ifs, choice)
data['Weekday_Weekend'] = np.select(ifs1, choice1)  # 0 for weekday, 1 for weekend
data['Month'] = data['Call_Date'].dt.strftime('%b')
data['Hour'] = data['Call_Date'].dt.hour
data.head()

#For Modelling purpose creating a new dataframe with only Call_Volume and Date as index
df = data[['Date','Call_Volume']]
df = df.groupby('Date')['Call_Volume'].sum().reset_index()
df['Date'] = pd.to_datetime(df['Date'], format="%d/%m/%Y")
df = df.set_index('Date')
#df['shift'] = df.Call_Volume.diff(2).dropna()
df.head()

"""NUMERICAL SUMMARY"""

#Numerical Summary
summary = df.describe()
totsum = df['Call_Volume'].sum()
totvar = df['Call_Volume'].var()
totskew = skew(df['Call_Volume'])
totkurt = kurtosis(df['Call_Volume'])
totcv = str(round(np.std(df['Call_Volume']) / np.mean(df['Call_Volume']) * 100,2))+'%'
statistic, p_value = shapiro(df['Call_Volume'])
summary.reset_index(inplace=True)
summary.loc[len(summary)] = ['sum', totsum]
summary.loc[len(summary)] = ['var', totvar]
summary.loc[len(summary)] = ['skew', totskew]
summary.loc[len(summary)] = ['kurtosis', totkurt]
summary.loc[len(summary)] = ['covar', totcv]
summary.loc[len(summary)] = ['Shapiroâ€“Wilk test(P-Value)', p_value]
summary = summary.set_index('index')
summary

data1 = data[['Date','Call_Volume','Day','Day_Name','Week','Weekday_Weekend','Month','MonthlyWeek']]
data1 = data1.groupby(['Date','Day','Day_Name','Week','Weekday_Weekend','Month','MonthlyWeek'])['Call_Volume'].sum().reset_index()

"""GRAPHICAL SUMMARY"""

sns.set_style("whitegrid")
fig, axes = plt.subplots(3, 3, figsize=(15, 15))
axes = axes.flatten()
# Plot monthly call volume trend
datap1 = data1[['Call_Volume','Month']]
datap1 = datap1.groupby('Month')['Call_Volume'].sum().reset_index()
sns.lineplot(x=datap1['Month'], y=datap1['Call_Volume'], marker='o', markersize=5, color='darkblue', linewidth=2,ax=axes[0])
axes[0].set_xlabel('Month')
axes[0].set_ylabel('Total Call Volume')
axes[0].set_title('(I) Monthly Call Volume Trend')
axes[0].tick_params(axis='x', rotation=45)
# Plot weekly call volume trend
datap2 = data1[['Call_Volume','Week']]
datap2 = datap2.groupby('Week')['Call_Volume'].sum().reset_index()
sns.lineplot(x=datap2['Week'], y=datap2['Call_Volume'], marker='o', markersize=5, color='darkblue', linewidth=2,ax=axes[1])
axes[1].set_xlabel('Week#')
axes[1].set_ylabel('Total Call Volume')
axes[1].set_title('(II) Weekly Call Volume Trend Between Mar-Sep')
axes[1].tick_params(axis='x', rotation=45)
# Plot Monthly weekly call volume trend
datap3 = data1[['Call_Volume','MonthlyWeek']]
datap3 = datap3.groupby('MonthlyWeek')['Call_Volume'].mean().reset_index()
sns.lineplot(x=datap3['MonthlyWeek'], y=datap3['Call_Volume'], marker='o', markersize=5, color='darkblue', linewidth=2,ax=axes[2])
axes[2].set_xlabel('Week')
axes[2].set_ylabel('Average Call Volume')
axes[2].set_title('(III) Weekly Call Volume Trend Overall Week Wise')
axes[2].tick_params(axis='x', rotation=45)
# Plot daily call volume trend
datap4 = data1[['Call_Volume','Day']]
datap4 = datap4.groupby('Day')['Call_Volume'].mean().reset_index()
sns.lineplot(x=datap4['Day'], y=datap4['Call_Volume'], marker='o', markersize=5, color='darkblue', linewidth=2,ax=axes[3])
axes[3].set_xlabel('Day')
axes[3].set_ylabel('Average Call Volume')
axes[3].set_title('(IV) Daily Call Volume Trend')
axes[3].tick_params(axis='x', rotation=45)
# Plot day wise call volume trend
datap5 = data1[['Call_Volume','Day_Name']]
datap5 = datap5.groupby('Day_Name')['Call_Volume'].mean().reset_index()
days_order = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']
datap5['Day_Name'] = pd.Categorical(datap5['Day_Name'], categories=days_order, ordered=True)
datap5 = datap5.sort_values(by='Day_Name')
sns.lineplot(x=datap5['Day_Name'], y=datap5['Call_Volume'], marker='o', markersize=5, color='darkblue', linewidth=2,ax=axes[4])
axes[4].set_xlabel('Day Name')
axes[4].set_ylabel('Average Call Volume')
axes[4].set_title('(V) Daily Call Volume Trend Day Wise')
axes[4].tick_params(axis='x', rotation=45)
# Plot hourly call volume trend
datahour = data[['Call_Volume','Hour']]
datahour = datahour.groupby('Hour')['Call_Volume'].sum().reset_index()
sns.lineplot(x=datahour['Hour'], y=datahour['Call_Volume'], marker='o', markersize=5, color='darkblue', linewidth=2,ax=axes[5])
axes[5].set_xlabel('Hours')
axes[5].set_ylabel('Total Call Volume')
axes[5].set_title('(VI) Hourly Call Volume Trend')
axes[5].tick_params(axis='x', rotation=45)
#Weekend/Weekday
dataweek = data1[['Call_Volume','Weekday_Weekend']]
dataweek = dataweek.groupby('Weekday_Weekend')['Call_Volume'].sum().reset_index()
sns.barplot(x=dataweek['Weekday_Weekend'], y=dataweek['Call_Volume'], color='darkblue',ax=axes[6])
axes[6].set_xlabel('Weekday/Weekend')
axes[6].set_ylabel('Total Call Volume')
axes[6].set_title('(VII) Weekday/Weekend Call Volume Trend')
axes[6].tick_params(axis='x', rotation=45)
for i in range(7, 9):
    axes[i].axis('off')
plt.tight_layout()
# plt.savefig('call_volume_trends.png')
plt.show()

"""DECOMPOSITION AND MOVING AVERAGES"""

from pylab import rcParams
import statsmodels.api as sm
rcParams['figure.figsize'] = 20,5
decomposition_mul = sm.tsa.seasonal_decompose(df.Call_Volume, model='multiplicative')
decomposition_add = sm.tsa.seasonal_decompose(df.Call_Volume, model='additive')
decomposition_add.plot()
decomposition_mul.plot()
#plt.savefig('Decomposition_Mul.png')
plt.show()

df['MA5'] = df['Call_Volume'].rolling(window=5).mean()
df['MA10'] = df['Call_Volume'].rolling(window=10).mean()
df['MA20'] = df['Call_Volume'].rolling(window=20).mean()
df['MA30'] = df['Call_Volume'].rolling(window=30).mean()

# Plot using Matplotlib
plt.figure(figsize=(20, 5))

# Plot original data
plt.plot(df['Call_Volume'], label='Original', color='blue')

# Plot moving averages
plt.plot(df['MA5'], label='MA5', color='yellow')
plt.plot(df['MA10'], label='MA10', color='green')
plt.plot(df['MA20'], label='MA20', color='red')
plt.plot(df['MA30'], label='MA30', color='orange')

# Add labels and title
plt.title('Moving Averages')
plt.xlabel('Month_Year')
plt.ylabel('Call_Volume')
plt.legend()
plt.savefig('MA.png')
# Show plot
plt.show()

"""STATIONARITY OF THE DATA"""

dfs = df
dfs['shift'] = dfs.Call_Volume.diff()
dfs.head()

def test_stat(df,var):
  df['rollmean'] = df[var].rolling(5).mean()
  df['rollstd'] = df[var].rolling(5).std()
  adf = adfuller(df[var],autolag = 'AIC')
  print(f'ADF Statistic: {adf[0]}')
  print(f'ADF - p-value: {adf[1]}')
  print(f'Lags Used: {adf[2]}')
  print(f'Ovservations: {adf[3]}')
  print(f'Critical Value: {adf[4]}')
  if adf[1] < 5/100:
    print('Data is Stationary')
  else:
    print('Data is NOT Stationary')

  plt.figure(figsize=(20,5))
  fact = plt.plot(df[var],color = 'blue',label = 'shift')
  mean = plt.plot(df.rollmean,color = 'red',label = 'rollMean')
  std = plt.plot(df.rollstd,color = 'black',label = 'rollStd')
  plt.legend(loc = 'best')
  plt.show(block = False)

test_stat(dfs.dropna(),'shift')

train_len = 184 #Considering 6 months to train the data
train = dfs[0:train_len+1] # first 5 months as training set
test = dfs[train_len:]

def error_check(df1,df2,meth):
  mse = mean_squared_error(df1, df2).round(3)
  mape = np.round(np.mean(np.abs(df1-df2)/df1)*100,2)
  mae = mean_absolute_error(df1, df2)
  results = pd.DataFrame({'Method':[meth], 'MAPE': [mape], 'MSE': [mse],'MAE': [mae]})
  results = results[['Method', 'MSE', 'MAPE','MAE']]
  return results

#Naive Forecast Method
naive = test.copy()
naive['forecast'] = train['shift'][train_len-1]#Call_Volume
naive_res = error_check(test['shift'],naive['forecast'],'Naive Forecast Model')
naive_res

#Mean Method
sim_mean = test.copy()
sim_mean['forecast'] = train['shift'].mean()
sim_mean_res = error_check(test['shift'],sim_mean['forecast'],'Simple Mean Model')
sim_mean_res

#Moving Average Method
mov_avg = test.copy()
mov_avg['forecast'] = train['shift'].rolling(30).mean().iloc[-1]
mov_avg_res = error_check(test['shift'],mov_avg['forecast'],'Moving Average Model')
mov_avg_res

#SES Method
ses = test.copy()
ses_fit = SimpleExpSmoothing(train['Call_Volume']).fit()
ses['forecast'] = ses_fit.forecast(len(test))
ses_res = error_check(test['Call_Volume'][1:],ses['forecast'].dropna(),'SES Model')
ses_res
ses_fit.summary()

#Simple Linear Regression Method
dfs['Lag_1'] = dfs['Call_Volume'].shift(1)
df_lag = dfs.copy().dropna()

# Training data
X_lag = df_lag[["Lag_1"]]  # feature
y_lag = df_lag.Call_Volume  # target
# Train the model
model_lag = LinearRegression()
model_lag.fit(X_lag, y_lag)
# Generate a series of predicted values from our lag data
y_lag_pred = pd.Series(model_lag.predict(X_lag))
lr_res = error_check(y_lag,y_lag_pred,'Linear Regression Model')
lr

#Holt Linear Model
holtl = test.copy()
holtl_fit = Holt(np.asarray(train['Call_Volume'])).fit()
holtl['forecast'] = holtl_fit.forecast(len(test))
holtl_res = error_check(test['Call_Volume'],holtl['forecast'].dropna(),'Holt Linear Model')
holtl_res
holtl_fit.summary()

#Holt Winters Model
holtw = test.copy()
holtw_fit = ExponentialSmoothing(train['Call_Volume'] ,seasonal_periods=7 , seasonal='add').fit()
holtw['forecast'] = holtw_fit.forecast(len(test))
holtw_res = error_check(test['Call_Volume'][1:],holtw['forecast'].dropna(),'Holt Winters Model')
holtw_res
holtw_fit.summary()

fig, axes = plt.subplots(2, 2, figsize=(15, 15))
axes = axes.flatten()

plot_pacf(train['Call_Volume'].dropna(),lags = 20, ax=axes[1],title='Non Stationary Data - PACF')
plot_acf(train['Call_Volume'].dropna(),lags = 20, ax=axes[0],title='Non Stationary Data - ACF')
plot_pacf(train['shift'].dropna(),lags = 20, ax=axes[3],title='Stationary Data - PACF')
plot_acf(train['shift'].dropna(),lags = 20, ax=axes[2],title='Stationary Data - ACF')

plt.show()

#ARIMA Model
arima = test.copy()
arima_fit1 = ARIMA(train['Call_Volume'], order=(7, 0, 8)).fit()
arima['forecast'] = arima_fit1.predict(start="2019-09-01", end="2019-09-30", dynamic=True)
arima_res = error_check(test['Call_Volume'],arima['forecast'],'ARIMA Model')
print(arima_res)
print(arima_fit1.summary())

#Auto Arima
autoamtest = auto_arima(train['Call_Volume'],
                    start_p = 0,
                    start_q = 0,
                    test = 'adf',
                    max_p = 9,
                    max_q = 9,
                    m = 1,
                    d=None,
                    trace = True,
                    error_acttion = 'warn',
                    suppress_warnings = True,
                    stepwise = True)

sarima = test.copy()
sarima_fit1 = SARIMAX(train['Call_Volume'], order=(1, 1, 1),seasonal_order=(0,1,1,7)).fit()
sarima['SARIMA'] = sarima_fit1.predict(start="2019-09-01", end="2019-09-30", dynamic=True)
sarima_res = error_check(test['Call_Volume'],sarima['SARIMA'],'SARIMA Model')
print(sarima_res)
print(sarima_fit1.summary())

sarima1 = test.copy()
sarima_fit2 = SARIMAX(train['Call_Volume'], order=(1, 2, 1),seasonal_order=(0,1,1,7)).fit()
sarima1['SARIMA'] = sarima_fit2.predict(start="2019-09-01", end="2019-09-30", dynamic=True)
sarima_res1 = error_check(test['Call_Volume'],sarima1['SARIMA'],'SARIMA Model')
print(sarima_res1)
print(sarima_fit2.summary())

plt.figure(figsize=(20,5))
plt.plot( train['Call_Volume'], label='Train')
plt.plot(test['Call_Volume'], label='Test')
plt.plot(naive['forecast'], label='Naive')
plt.plot(sim_mean['forecast'], label='Simple Mean')
plt.plot(mov_avg['forecast'], label='Moving Average')
plt.plot(ses['forecast'], label='SES')
#plt.plot(y_lag_pred, label='Simple Linear Regression')
plt.plot(holtl['forecast'], label='Holt Linear')
plt.plot(holtw['forecast'], label='Holt Winter')
plt.title('Train vs Test vs Models')
plt.legend(loc='best')
plt.show()

plt.figure(figsize=(20,5))
plt.plot( train['Call_Volume'], label='Train')
plt.plot(test['Call_Volume'], label='Test')
plt.plot(arima['forecast'], label='ARIMA(7,0,8)')
plt.plot(sarima['SARIMA'], label='SARIMA (1, 1, 1)x(0, 1, 1, 7)')
plt.plot(sarima1['SARIMA'], label='SARIMA (1, 2, 1)x(0, 1, 1, 7)')
plt.title('Train vs Test vs ARIMA Models')
plt.legend(loc='best')
plt.show()

residuals = sarima_fit2.resid

# Create Q-Q plot
qqplot(residuals, line='s')
plt.title('Q-Q Plot for SARIMAX Residuals')
plt.show()

"""FORECAST 2 MONTHS DATA"""

futureDates = pd.DataFrame(pd.date_range(start='2019-10-01', end='2019-11-30'),columns=['Dates'])
futureDates.set_index('Dates',inplace=True)
#futureDates

futureDates['Forecast'] = round(sarima_fit2.predict(start=futureDates.index[0], end=futureDates.index[-1]))

plt.figure(figsize=(20,5))
plt.plot( train['Call_Volume'], label='Train')
plt.plot(test['Call_Volume'], label='Test')
plt.plot(sarima1['SARIMA'], label='SARIMA (1, 2, 1)x(0, 1, 1, 7)')
plt.plot(futureDates['Forecast'], label ='Forecast' )
plt.title('Final Forecast')
plt.legend(loc='best')
plt.show()

plt.figure(figsize=(20, 5))
plt.plot(df.index, df['Call_Volume'], label='Actual', color='blue')
plt.plot(sarima_fit2.fittedvalues.index, sarima_fit2.fittedvalues, label='Fitted', color='green', linestyle='--')
plt.plot(futureDates.index, futureDates['Forecast'], label='Forecast', color='red', linestyle='--')
plt.fill_between(futureDates.index, futureDates['Forecast'] - sarima_fit2.fittedvalues.std(), futureDates['Forecast'] + sarima_fit2.fittedvalues.std(), color='pink', alpha=0.3)
plt.title('SARIMA Forecast with Confidence Intervals')
plt.xlabel('Date')
plt.ylabel('Value')
plt.legend()
plt.show()

final_table = pd.concat([df['Call_Volume'],futureDates['Forecast']])
final_table

final_table.to_csv('Forecast.csv')